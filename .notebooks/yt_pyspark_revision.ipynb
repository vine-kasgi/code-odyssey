{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63caed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Session\n",
    "from pyspark.sql import SparkSession,DataFrame\n",
    "spark: SparkSession = SparkSession.builder.appName(\"yt_pyspark_revision\").getOrCreate() # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f32ef093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Data\n",
    "customer_data = [\n",
    "    (1, 101),\n",
    "    (1, 102),\n",
    "    (1, 104),\n",
    "    (2, 101),\n",
    "    (3, 102),\n",
    "    (3, 101),\n",
    "    (3, 103),\n",
    "    (4, 101),\n",
    "    (4, 102),\n",
    "    (4, 104),\n",
    "    (4, 103),\n",
    "    (4, 103)\n",
    "]\n",
    "# Product Data\n",
    "product_data = [\n",
    "    (101,),\n",
    "    (102,),\n",
    "    (103,)\n",
    "]\n",
    "\n",
    "# Schema\n",
    "customer_schema = \"customer_id int, product_key int\"\n",
    "product_schema = \"product_key int\"\n",
    "\n",
    "# Product df\n",
    "product_df : DataFrame = spark.createDataFrame(data = product_data, schema= product_schema)\n",
    "customer_df : DataFrame = spark.createDataFrame(data = customer_data,schema=customer_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5fe1bec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Product DataFrame**********\n",
      "+-----------+\n",
      "|product_key|\n",
      "+-----------+\n",
      "|        101|\n",
      "|        102|\n",
      "|        103|\n",
      "+-----------+\n",
      "\n",
      "**********Customer DataFrame**********\n",
      "+-----------+-----------+\n",
      "|customer_id|product_key|\n",
      "+-----------+-----------+\n",
      "|          1|        101|\n",
      "|          1|        102|\n",
      "|          1|        104|\n",
      "|          2|        101|\n",
      "|          3|        102|\n",
      "|          3|        101|\n",
      "|          3|        103|\n",
      "|          4|        101|\n",
      "|          4|        102|\n",
      "|          4|        104|\n",
      "|          4|        103|\n",
      "|          4|        103|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"**********Product DataFrame**********\")\n",
    "product_df.show()\n",
    "print(\"**********Customer DataFrame**********\")\n",
    "customer_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9df35527",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_count = product_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d62c723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, countDistinct, collect_set, concat_ws, count\n",
    "joined_df = customer_df.join(product_df, on=customer_df.product_key == product_df.product_key, how='inner') \\\n",
    "    .select(customer_df.customer_id, customer_df.product_key)\n",
    "\n",
    "result = joined_df.groupBy(\"customer_id\").agg(count('product_key').alias(\"count\"), concat_ws(\", \", collect_set(\"product_key\")).alias(\"products\")) \\\n",
    "    .filter(f'count == {product_count}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "218154c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------------+\n",
      "|customer_id|count|     products|\n",
      "+-----------+-----+-------------+\n",
      "|          3|    3|102, 103, 101|\n",
      "+-----------+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1edbf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+---------------+\n",
      "|customer_id|count|       products|\n",
      "+-----------+-----+---------------+\n",
      "|          3|    3|[103, 102, 101]|\n",
      "|          4|    3|[103, 102, 101]|\n",
      "+-----------+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sort_array,collect_list,asc,countDistinct,array_distinct\n",
    "\n",
    "s = joined_df.groupBy(\"customer_id\") \\\n",
    "    .agg(countDistinct('product_key').alias(\"count\"), sort_array(array_distinct(collect_list(\"product_key\")), asc = False).alias(\"products\")) \\\n",
    "    .filter(f'count == {product_count}')\n",
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b6244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7096a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1520af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5494aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c70c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Manual)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
